---
title: "modelo"
author: "Rodolfo Viana"
date: "05-12-2015"
output: html_document
---

Carregando as bibliotecas necessárias 

```{r}
library(h2o)
require(caret)
library(ggplot2)
conn <- h2o.init(nthreads = -1)
```

Inicalmente vamos dividir o dataset entre o data set de treino e validação. Essa divisão é importante por evita o overfitting prod_qty_treino_novas_variaveis

```{r}
# Importando arquivo no h2o
path_input <- "/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/Dados/prod_qty_treino.csv"
data <- h2o.importFile(path = path_input, destination_frame = "train.hex")


# Divide o data frame em dois. treino 80 / validação  20 
data.split <- h2o.splitFrame(data = data , ratios = 0.80)

# Treino 
data.train <- data.split[[1]] 

# Validação
data.validacao <- data.split[[2]]
```


A minha estrategia é primeiro achar o melhor modelo que encontre a quatidade diária que será vendida para cada produto, para só depois encontrar o melhor modelo que encontre o preço diário desse produto.
Vamos inicialmente trabalhar com os modelos GBM, Árvore Aleatória e GLM. O ideal seria inicialmente rodar todos os modelos com um grande número de árvores, grande profundidade e uma taxa de aprendizado pequena por interação. Porém isso leva um tempo especialmente grande rodando na minha máquina atual (apenas 4GB)

```{r}
myY <- "qty"
ignored_columns <- "preco"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)

# GBM
gbm <- h2o.gbm(x = myX, build_tree_one_node = T, 
             y = myY,
             training_frame    = data.train,
             validation_frame  = data.validacao,
             ntrees            = 50,
             max_depth         = 6,
             learn_rate        = 0.1)

# DRF
drf <- h2o.randomForest(x = myX,
                      y = myY,
                      training_frame    = data.train,
                      validation_frame  = data.validacao,
                      ntrees            = 50,
                      max_depth         = 30)

# GLM
glm <- h2o.glm(x = myX,
             y = myY,
             training_frame    = data.train,
             validation_frame  = data.validacao,
             lambda            = 1e-5,
             family            = "poisson")



# Score de cada modelo
train_r2_gbm <- h2o.r2(gbm)
test_r2_gbm  <- h2o.r2(gbm, valid = TRUE)
print(paste0("GBM R2 TRAIN = ", train_r2_gbm, ", R2 TEST = ", test_r2_gbm))

train_r2_drf <- h2o.r2(drf)
test_r2_drf  <- h2o.r2(drf, valid = TRUE)
print(paste0("DRF R2 TRAIN = ", train_r2_drf, ", R2 TEST = ", test_r2_drf))

train_r2_glm <- h2o.r2(glm)
test_r2_glm  <- h2o.r2(glm, valid = TRUE)
print(paste0("GLM R2 TRAIN = ", train_r2_glm, ", R2 TEST = ", test_r2_glm))

df <- data.frame(r2 = c(train_r2_gbm, test_r2_gbm, train_r2_drf, test_r2_drf, train_r2_glm, test_r2_glm),
                         tipo = c("treino", "validacao", "treino", "validacao", "treino", "validacao"), 
                         modelo = c("GBM","GBM","RF", "RF","GLM", "GLM"))

ggplot(data=df, aes(x=modelo, y=r2, fill=tipo)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme_classic() + 
  theme(axis.ticks = element_blank())

```

Como o Random florest teve um melhor resultado do que os outros modelos, obtendo assim um R2 maior, então optamos por escolher o Random Florest para o caso da predição da quantidade de vendas de produtos.

Como o Random Florest foi o escolhido, é interessante observar como se deu o treinamento ao longo das criações das árvores. Para evitar o overfitting dividimos os dados de teste em treino e validação. Dessa forma podemos observar o exato momento em que o modelo passa a sofrer o overfitting. 


```{r}

```

É possível notar que depois da árvore 17, o modelo passa a sofrer overfitting. Por esse motivo criamos um novo modelo, porém dessa vez parando o treinamento na árvore 17. A linha azul significa o treino e a linha laranja significa validação. 


```{r}
# DRF
drf <- h2o.randomForest(x = myX,
                      y = myY,
                      training_frame    = data.train,
                      validation_frame  = data.validacao,
                      ntrees            = 17,
                      max_depth         = 30)


novo_train_r2_drf <- h2o.r2(drf)
novo_test_r2_drf  <- h2o.r2(drf, valid = TRUE)
print(paste0("DRF R2 TRAIN = ", train_r2_drf, ", R2 TEST = ", test_r2_drf))

df <- data.frame(r2 = c(train_r2_drf, test_r2_drf, novo_train_r2_drf, novo_test_r2_drf),
                         tipo = c("treino", "validacao", "treino", "validacao"), 
                         modelo = c("Antigo", "Antigo", "Novo", "Novo"))

ggplot(data=df, aes(x=modelo, y=r2, fill=tipo)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme_classic() + 
  theme(axis.ticks = element_blank())
```

É possível notar que o valor de R2 do treino sofreu uma ligeira queda, porém o valor do R2 sofreu um aumento. Dessa forma a gente evita o overfitting

```{r}
#Novo gráfico da evolução

```

É interessante notar também a importância das variáveis para a criação dos modelos. 

```{r}


```

Notamos que a variável PROD_ID, dia e semana foram as variáveis com maior importância para a criação do modelo. Por esse motivo é interessante investigar essas variáveis para melhorar o modelo. 

Uma boa alternativa é criar uma váriavel que mostre a quantidade de compras que o item teve no dia anterior. Outra boa alternativa é criar uma váriavel que mostre a média de preço e a quantidade de compras do item na última semana. 

Foi feito então um novo pré processamento, onde foi adicionado as três novas colunas *qty_semana*, *media_preco_semana*, *qty_anterior*. 

```{r}
# Importando arquivo no h2o
path_input <- "/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/Dados/prod_qty_treino_novas_variaveis.csv"
data <- h2o.importFile(path = path_input, destination_frame = "train.hex")


# Divide o data frame em dois. treino 80 / validação  20 
data.split <- h2o.splitFrame(data = data , ratios = 0.80)

# Treino 
data.train <- data.split[[1]] 

# Validação
data.validacao <- data.split[[2]]
```

Um novo modelo será criado, seguindo os mesmo passos anteriores: 
1) Rodar RF com 50 árvores e 30 de profundidade (Esse número deveria ser bem mais alto, porém por motivos de processamento esse valors foram escolhidos)
2) Encontrar o ponto onde o modelo fica super especialista (overfitthing)
3) Rodar RF com o número de árvores otimizado

```{r}
myY <- "qty"
ignored_columns <- "preco"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)

# DRF
drf <- h2o.randomForest(x = myX,
                      y = myY,
                      training_frame    = data.train,
                      validation_frame  = data.validacao,
                      ntrees            = 50,
                      max_depth         = 30)
```

Para esse novo modelo com 50 árvores e 30 de profundidade não foi possível notar o ponto onde o modelo fica super especialista. Por esse motivo foi criado um novo modelo, dessa vez utilizando 100 árvores e 30 de profundidade. 


```{r}
myY <- "qty"
ignored_columns <- "preco"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)

# DRF
drf <- h2o.randomForest(x = myX,
                      y = myY,
                      training_frame    = data.train,
                      validation_frame  = data.validacao,
                      ntrees            = 100,
                      max_depth         = 30)
```

```{r}
# Evolução do treinamento

```

É possível notar que depois da árvore 60, tanto o treinamento quando a validação praticamente se estabilizam. Por esse motivo, o número de árvores ideal para esse conjunto de dados é 60. 

```{r}
myY <- "qty"
ignored_columns <- "preco"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)

# DRF
drf <- h2o.randomForest(x = myX,
                      y = myY,
                      training_frame    = data.train,
                      validation_frame  = data.validacao,
                      ntrees            = 60,
                      max_depth         = 30)

novas_variaveis_train_r2_drf <- h2o.r2(drf)
novas_variaveis_test_r2_drf  <- h2o.r2(drf, valid = TRUE)
```

Podemos agora compara e existiu algum ganho entre o melhor modelo com as novas variáveis 

```{r}
df <- data.frame(r2 = c(novo_train_r2_drf, novo_test_r2_drf, novas_variaveis_train_r2_drf, novas_variaveis_test_r2_drf),
                         tipo = c("treino", "validacao", "treino", "validacao"), 
                         modelo = c("Antigo", "Antigo", "Novo", "Novo"))

ggplot(data=df, aes(x=modelo, y=r2, fill=tipo)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme_classic() + 
  theme(axis.ticks = element_blank())
```

É possível notar que o valor do R2 subiu em relação ao modelo anterior. Devemos agora investigar quais foram as variáveis que mais contribuiram essa mudança.

```{r}
# Variable importance

```

É possível notar que as três novas variáveis adicionadas se encontram no Top 5 das variáveis que mais contribuiram para a criação do modelo. Podemos afimar então, que as novas variáveis influênciaram possitivamente o modelo.


Vamos agora repetir os passos para criar um novo modelo, para prever o preço de um certo produto por dia. 

```{r}
myY <- "preco"
ignored_columns <- "qty"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)

# DRF
drf_preco <- h2o.randomForest(x = myX,
                      y = myY,
                      training_frame    = data.train,
                      validation_frame  = data.validacao,
                      ntrees            = 50,
                      max_depth         = 30)

preco_train_r2_drf <- h2o.r2(drf)
preco_test_r2_drf  <- h2o.r2(drf, valid = TRUE)
```

É possível notar que o após 17 árvores o modelo se torna super especialista. Por esse motivo foi criado um novo modelo com apenas 17 árvores. 



```{r}
# Plot da evolução

```

Novo modelo

```{r}
myY <- "preco"
ignored_columns <- "qty"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)

# DRF
drf_preco <- h2o.randomForest(x = myX,
                      y = myY,
                      training_frame    = data.train,
                      validation_frame  = data.validacao,
                      ntrees            = 17,
                      max_depth         = 30)
```

Agora o modelo não sofre mais overfthing

```{r}
# Plot da evolução

```

É importante observar quais foram as variáveis quem mais contribuiram para a criação do modelo. 

```{r}
# Plot da evolução

```


Com isso temos dois modelos finais: 
1) Criado para prever a quantidade diária que será vendida de cada produto
2) Criado para prever o preço diário de cada produto

Podemos agora utilizar os dados de teste (que foi sepado antes do modelo e que é totalmente disjunto dos dados de treino) para prever qual seria o resultado em um mundo real. 

```{r}
# Importanto arquivo de teste no H2O
path_test <- "/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/Dados/prod_qty_test_novas_variaveis.csv"
data_train <- h2o.importFile(path = path_test, destination_frame = "test.hex")

drf.qty = h2o.predict(object = drf, newdata = data_train)
h2o.exportFile(drf.qty, path = "/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/Dados/predicao_qty.csv")

drf.preco = h2o.predict(object = drf_preco, newdata = data_train)
h2o.exportFile(drf.preco, path = "/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/Dados/predicao_preco.csv")
```

Podemos agora simular qual seria o real valor R2 no mundo real 

```{r}
prod_qty_test_novas_variaveis <- read.csv("~/Projetos/Desafio-Precificacao/Scripts/Dados/prod_qty_test_novas_variaveis.csv")

predicao_qty <- read.table("~/Projetos/Desafio-Precificacao/Scripts/Dados/predicao_qty.csv", header=TRUE, quote="\"")

avaliacao_qty <- data.frame(obs = prod_qty_test_novas_variaveis$qty, pred = predicao_qty$predict)

defaultSummary(avaliacao_qty)[[2]]

```

```{r}
predicao_preco <- read.table("~/Projetos/Desafio-Precificacao/Scripts/Dados/predicao_preco.csv", header=TRUE, quote="\"")

avaliacao_preco <- data.frame(obs = prod_qty_test_novas_variaveis$preco, pred = predicao_preco$predict)

defaultSummary(avaliacao_preco)[[2]]
```

É possível notar que o R2 ficou acima de 0.97 para os dois casos. Esse valor em um mundo real pode é considerado bastante alto. Cheguei nesse valor tão alto por se tratar de um conjunto de dados no qual não condiz o de um mundo real (ter apenas 9 produtos, 6 concorrentes, etc) todos esses fatores influenciaram para se ter um modelo com uma precisão tão alta. 

Mesmo com um valor alto, ainda é possível melhorar sem causar overfitting. Se eu tivesse mais tempo iria criar um novo modelo retirando alguns outlier, pois acredito que eles influênciam negativamente o modelo. Além disso, iria investigar e criar novas variáveis para melhorar o modelo. Algumas variáveis que acredito ter pontencial para melhorar o modelo seria:

1) Vendabilidade - Proporção que o produto foi comprado em realação aos outros produtos 

Acredito que seja importante para o modelo saber quais são os produtos com maior potencial de compras

2) Top_meses - Proporção de vendas de um mês em relação aos outros meses.

Acredito que seja importante para o modelo saber quais são os meses que mais possuem compras (Ex: Dia das mãe, pais, etc)

3) Dia_Mes - Mostra se o dia se encontra no começo, meio e fim do mês 

Acredito que algumas pessoas preferem comprar no começo do mês (quando recebem o salário) outras devem preferir comprar no fim do mês

Também acho importante utilizar outra biblioteca além do h2o, como por exemplo o caret que eu já usei aqui http://rpubs.com/Rodolfo_Viana/99497