---
title: "Modelo"
author: "Rodolfo Viana"
date: "04-12-2015"
output: html_document
---

Para a criação do modelo utilizei a biblioteca h2o, por se tratar de um open-source software para big-data analysis. O h2o é bastante rápido e flexível, podendo assim ser possível carregar uma grande quantidade de dados. Faz parte de uma comunidade que vem crescendo cada dia mais.
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
# Carregando as bibliotecas necessárias
library(dplyr)
library(ggplot2)
 
source("~/Projetos/Desafio-Precificacao/Scripts/R/precificacao-lib.R")
conn <- h2o.init(nthreads = -1)
```
 
Inicialmente vamos dividir o dataset entre o dataset de treino e validação. Essa divisão é importante por evita o overfitting, que ocorre quando um modelo estatístico super se adapta ao conjunto treinado, dessa forma quando o modelo recebe um valor pelo o qual ele não foi treinado, ele vai gerar uma predição muito ruim. É importante essa divisão entre treino e validação para verificar em qual ponto o modelo começa a sofrer overfitting.
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
# Importando arquivo no h2o
path_input <- "/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/Dados/prod_qty_treino.csv"
data <- h2o.importFile(path = path_input, destination_frame = "train.hex")
 
# Divide o data frame em dois. Treino 80 %/ validação  20%
data.split <- h2o.splitFrame(data = data , ratios = 0.80)
 
# Treino
data.train <- data.split[[1]]
 
# Validação
data.validacao <- data.split[[2]]
```
 
A minha estratégia é primeiro achar o melhor modelo que encontre a quantidade diária que será vendida para cada produto, e só depois encontrar o melhor modelo que encontre o preço diário desse produto.
 
Vamos inicialmente trabalhar com os modelos GBM, random florest e GLM. O ideal seria inicialmente rodar todos os modelos com um grande número de árvores, grande profundidade e uma taxa de aprendizado pequena por interação, porém isso leva um tempo grande na minha máquina atual (com apenas 4GB)
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
# Coluna que se deseja prever
myY <- "qty"
 
# Coluna que deve ser ignorada pelo modelo
ignored_columns <- "preco"
 
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)
 
# GBM
gbm <- h2o.gbm(x = myX, build_tree_one_node = T,
            y = myY,
            training_frame    = data.train,
            validation_frame  = data.validacao,
            ntrees            = 50,
            max_depth         = 6,
            learn_rate        = 0.1)
 
# DRF
drf <- h2o.randomForest(x = myX,
                     y = myY,
                     training_frame    = data.train,
                     validation_frame  = data.validacao,
                     ntrees            = 50,
                     max_depth         = 30)
 
# GLM
glm <- h2o.glm(x = myX,
            y = myY,
            training_frame    = data.train,
            validation_frame  = data.validacao,
            lambda            = 1e-5,
            family            = "poisson")
 
# Score de cada modelo
train_r2_gbm <- h2o.r2(gbm)
test_r2_gbm  <- h2o.r2(gbm, valid = TRUE)
 
train_r2_drf <- h2o.r2(drf)
test_r2_drf  <- h2o.r2(drf, valid = TRUE)
 
train_r2_glm <- h2o.r2(glm)
test_r2_glm  <- h2o.r2(glm, valid = TRUE)
 
df <- data.frame(Rsquared = c(train_r2_gbm, test_r2_gbm, train_r2_drf, test_r2_drf, train_r2_glm, test_r2_glm),
                        tipo = c("treino", "validacao", "treino", "validacao", "treino", "validacao"),
                        modelo = c("GBM","GBM","RF", "RF","GLM", "GLM"))
```
 
Para verificar qual dos 3 modelos é o melhor, utilizamos a métrica Rsquared, onde o valor do Rsquared (entre 0 e 1) é o percentual de variância explicada pelo o modelo. Quanto maior foi o Rsquared melhor é o modelo.
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
ggplot(data=df, aes(x = modelo, y = Rsquared, fill = tipo)) +
 geom_bar(stat="identity", position=position_dodge()) +
 theme_classic() +
 labs(title = "Comparando os modelos") +
 theme(axis.ticks = element_blank())
```
 
É possível notar que o Random Florest teve um melhor resultado do que os outros modelos, obtendo assim um Rsquared maior, então optamos por escolher o Random Florest para o caso da predição da quantidade de vendas de produtos.
 
Como o Random Florest foi o escolhido, é interessante observar como se deu o treinamento ao longo das criações das árvores. Para evitar o overfitting dividimos os dados de treino em treino e validação. Dessa forma podemos observar o exato momento em que o modelo passa a sofrer o overfitting.
 
<div style="text-align:center" markdown="1">
![treinamento](/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/plots/RF_50_30.png)
</div>
É possível notar que depois da árvore 17, o modelo passa a sofrer overfitting. Por esse motivo criamos um novo modelo, dessa vez parando o treinamento na árvore 17. A linha azul significa a evolução do treino e a linha laranja significa validação.
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
# DRF
drf <- h2o.randomForest(x = myX,
                     y = myY,
                     training_frame    = data.train,
                     validation_frame  = data.validacao,
                     ntrees            = 17,
                     max_depth         = 30)
 
novo_train_r2_drf <- h2o.r2(drf)
novo_test_r2_drf  <- h2o.r2(drf, valid = TRUE)
 
df <- data.frame(Rsquared = c(train_r2_drf, test_r2_drf, novo_train_r2_drf, novo_test_r2_drf),
                        tipo = c("treino", "validacao", "treino", "validacao"),
                        modelo = c("Antigo", "Antigo", "Novo", "Novo"))
 
ggplot(data=df, aes(x = modelo, y = Rsquared, fill = tipo)) +
 geom_bar(stat = "identity", position = position_dodge()) +
 labs(title = "Comparando RF") +
 theme_classic() +
 theme(axis.ticks = element_blank())
```
 
É possível notar que o valor de Rsquared do treino sofreu uma ligeira queda, porém o valor do Rsquared da validação sofreu um aumento. Dessa forma a gente evita o overfitting
 
Evolução do treinamento
<div style="text-align:center" markdown="1">
![treinamento](/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/plots/RF_17_30.png)
</div>
É interessante notar também a importância das variáveis para a criação dos modelos.
<div style="text-align:center" markdown="1">
![treinamento](/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/plots/RF_17_30_variable_importances.png)
</div>
Notamos que a variável **PROD_ID, dia e semana** foram as variáveis com maior importância para a criação do modelo. Por esse motivo é interessante criar novas variáveis que podem agregar valor a essas variáveis para melhorar o modelo.
 
Uma boa alternativa é criar uma variável que mostre a quantidade de compras que o item teve no dia anterior. Outra boa alternativa é criar uma variável que mostre a média de preço e a quantidade de compras do item na última semana.
 
Foi feito então um novo pré-processamento, onde foram adicionadas as três novas colunas **qty_semana, media_preco_semana, qty_anterior**.
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
# Importando arquivo no h2o
path_input <- "/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/Dados/prod_qty_treino_novas_variaveis.csv"
data <- h2o.importFile(path = path_input, destination_frame = "train.hex")
 
# Divide o data frame em dois. treino 80 / validação  20
data.split <- h2o.splitFrame(data = data , ratios = 0.80)
 
# Treino
data.train <- data.split[[1]]
 
# Validação
data.validacao <- data.split[[2]]
```
 
Um novo modelo será criado, seguindo os mesmo passos anteriores:
* Rodar RF com 50 árvores e 30 de profundidade
* Encontrar o ponto onde o modelo começa a ficar especialista (overfitthing)
* Rodar RF com o número de árvores otimizado
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
myY <- "qty"
ignored_columns <- "preco"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)
 
# DRF
drf <- h2o.randomForest(x = myX,
                     y = myY,
                     training_frame    = data.train,
                     validation_frame  = data.validacao,
                     ntrees            = 50,
                     max_depth         = 30)
```
<div style="text-align:center" markdown="1">
![treinamento](/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/plots/RF_50_30_n_variaveis.png)
</div>
Para esse novo modelo não foi possível notar o ponto onde o modelo começa a ficar especialista. Por esse motivo foi criado um novo modelo, dessa vez utilizando 100 árvores e 30 de profundidade.
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
myY <- "qty"
ignored_columns <- "preco"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)
 
# DRF
drf <- h2o.randomForest(x = myX,
                     y = myY,
                     training_frame    = data.train,
                     validation_frame  = data.validacao,
                     ntrees            = 100,
                     max_depth         = 30)
```
<div style="text-align:center" markdown="1">
![treinamento](/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/plots/RF_100_30.png)
</div>
É possível notar que depois da árvore 60, tanto o treinamento quando a validação se estabilizam. Por esse motivo, o número de árvores ideal para esse conjunto de dados é 60 (com mais árvores só estaríamos "desperdiçando" processamento para ter pouca melhora no modelo).
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
myY <- "qty"
ignored_columns <- "preco"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)
 
# DRF
drf <- h2o.randomForest(x = myX,
                     y = myY,
                     training_frame    = data.train,
                     validation_frame  = data.validacao,
                     ntrees            = 60,
                     max_depth         = 30)
 
novas_variaveis_train_r2_drf <- h2o.r2(drf)
novas_variaveis_test_r2_drf  <- h2o.r2(drf, valid = TRUE)
```
 
Podemos agora compara e verificar se existiu algum ganho entre o melhor modelo com as novas variáveis
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
df <- data.frame(Rsquared = c(novo_train_r2_drf, novo_test_r2_drf,
                       novas_variaveis_train_r2_drf, novas_variaveis_test_r2_drf),
                        tipo = c("treino", "validacao", "treino", "validacao"),
                        modelo = c("Antigo", "Antigo", "Novo", "Novo"))
 
ggplot(data = df, aes(x = modelo, y = Rsquared, fill = tipo)) +
 geom_bar(stat = "identity", position = position_dodge()) +
 labs(title = "Comparando RF com Novas Variáveis") +
 theme_classic() +
 theme(axis.ticks = element_blank())
```
 
É possível notar que o valor do Rsquared subiu em relação ao modelo anterior. Devemos agora investigar quais foram as variáveis que mais contribuíram para essa mudança.
<div style="text-align:center" markdown="1">
![treinamento](/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/plots/RF_60_30_variable_importance.png)
</div>
Notamos que as três novas variáveis adicionadas se encontram no Top 5 das variáveis que mais contribuíram para a criação do modelo. Podemos afirmar então, que as novas variáveis influenciaram positivamente o modelo.
 
*******
 
## Modelo para prever o preço de um certo produto por dia
 
Vamos agora repetir os passos para criar um novo modelo, para prever o preço de um certo produto por dia.
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
myY <- "preco"
ignored_columns <- "qty"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)
 
# DRF
drf_preco <- h2o.randomForest(x = myX,
                     y = myY,
                     training_frame    = data.train,
                     validation_frame  = data.validacao,
                     ntrees            = 50,
                     max_depth         = 30)
```
<div style="text-align:center" markdown="1">
![treinamento](/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/plots/preco_RF_50_30.png)
</div>
É possível notar que o após 17 árvores o modelo se torna especialista. Por esse motivo foi criado um novo modelo com apenas 17 árvores.
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
myY <- "preco"
ignored_columns <- "qty"
myX <- setdiff(setdiff(names(data.train), myY), ignored_columns)
 
# DRF
drf_preco <- h2o.randomForest(x = myX,
                     y = myY,
                     training_frame    = data.train,
                     validation_frame  = data.validacao,
                     ntrees            = 17,
                     max_depth         = 30)
```
 
Agora o modelo não sofre mais overfitting
<div style="text-align:center" markdown="1">
![treinamento](/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/plots/preco_17_30.png)
</div>
É importante observar quais foram as variáveis quem mais contribuíram para a criação do modelo.
<div style="text-align:center" markdown="1">
![treinamento](/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/plots/preco_RF_17_30_variable_importance.png)
</div>
É interessante notar que o concorrente C1 se encontra no Top 3 das variáveis que mais contribuíram para a criação do modelo. Esse mesmo concorrente foi destacado como sendo o concorrente que possui os melhores preços antes mesmo da criação de qualquer modelo
 
Com isso temos dois modelos finais:
* Um modelo para prever a quantidade diária que será vendida de cada produto
* Um modelo para prever o preço diário de cada produto
 
*****
 
## Prevendo o preço e a quantidade
 
Podemos agora utilizar os dados de teste (que foi separado antes do modelo, e que é totalmente disjunto dos dados de treino) para prever qual seria o resultado em um mundo real.
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
# Importanto arquivo de teste no H2O
path_test <- "/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/Dados/prod_qty_test_novas_variaveis.csv"
data_train <- h2o.importFile(path = path_test, destination_frame = "test.hex")
 
drf.qty = h2o.predict(object = drf, newdata = data_train)
h2o.exportFile(drf.qty, path = "/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/Dados/predicao_qty.csv")
 
drf.preco = h2o.predict(object = drf_preco, newdata = data_train)
h2o.exportFile(drf.preco, path = "/home/rodolfo/Projetos/Desafio-Precificacao/Scripts/Dados/predicao_preco.csv")
```
 
Podemos agora simular qual seria o real valor Rsquared no mundo real. Para o modelo que prever a quantidade de compras, temos um Rsquared de:
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
prod_qty_test_novas_variaveis <- read.csv("~/Projetos/Desafio-Precificacao/Scripts/Dados/prod_qty_test_novas_variaveis.csv")
 
predicao_qty <- read.table("~/Projetos/Desafio-Precificacao/Scripts/Dados/predicao_qty.csv", header=TRUE, quote="\"")
 
avaliacao_qty <- data.frame(obs = prod_qty_test_novas_variaveis$qty, pred = predicao_qty$predict)
 
defaultSummary(avaliacao_qty)[[2]]
```
 
Para o modelo que prever a quantidade o preço, temos um Rsquared de:
 
```{r, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
predicao_preco <- read.table("~/Projetos/Desafio-Precificacao/Scripts/Dados/predicao_preco.csv", header=TRUE, quote="\"")
 
avaliacao_preco <- data.frame(obs = prod_qty_test_novas_variaveis$preco, pred = predicao_preco$predict)
 
defaultSummary(avaliacao_preco)[[2]]
```
 
É possível notar que o Rsquared ficou acima de 0.97 para os dois casos. Esse valor no mundo real é considerado bastante alto. Cheguei nesse valor tão alto por se tratar de um conjunto de dados no qual não condiz com o de um mundo real (ter apenas 9 produtos, 6 concorrentes, etc). Todos esses fatores influenciaram para se ter um modelo com uma precisão tão alta.
 
Mesmo com um valor alto, ainda é possível melhorar sem causar overfitting. Se eu tivesse mais tempo, iria criar um novo modelo retirando alguns outlier, pois acredito que eles influênciam negativamente o modelo. Também iria retirar as variáveis que pouco contribuem para o modelo, deixando ele assim mais rápido.
 
Além disso, iria investigar e criar novas variáveis para melhorar o modelo. Algumas variáveis que tem potencial para melhorar o modelo:
 
* Vendabilidade - Proporção que o produto foi comprado em relação aos outros produtos
 
Acredito que ser importante para o modelo saber quais são os produtos com maior potencial de compras
 
* Top_meses - Proporção de vendas de um mês em relação aos outros meses.
 
Acredito que ser  importante para o modelo saber quais são os meses que mais possuem compras (Ex: Dia das mãe, pais, etc)
 
* Dia_Mes - Mostra se o dia se encontra no começo, meio ou fim do mês
 
Acredito que algumas pessoas preferem comprar no começo do mês (quando recebem o salário) outras devem preferir comprar no fim do mês
 
Também acho importante utilizar outra biblioteca além do h2o, como por exemplo, o caret, que eu já usei [aqui](http://rpubs.com/Rodolfo_Viana/99497)
